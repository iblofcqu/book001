# 强化学习算法参数设定

多智能体强化学习MARL的参数设置如表5.2所示。为确保每次仿真验证的独立性，Q-Table中存储的知识经验在每次仿真中均被清零。并且，多个智能体的起点和终点，障碍物的位置在每次仿真中也均被重置。当一个智能体成功到达目标点且未与障碍物发生碰撞或超过规定的运行时间时，则定义为一次成功。因此，多智能体系统的成功率(
success rate，$S_r$)
定义为在总训练代数中，所有智能体成功到达目标点且未与障碍物发生碰撞或未超过规定的运行时间的比例，可以由公式（5-3）计算所得：

$$

S_r = \dfrac {1} {N_m} ×∑_{i=1}^{N_m} \dfrac {N_s^i} {N_s} ×100\% \tag {5-3}

$$

其中，$N_m$为总的训练代数，$N_s$是一次任务中总智能体数目，$N_s^i$是任务i中成功到达终点且无发生碰撞的智能体总数。$S_r$指标被用来评估强化学习MARL的训练效果。

:::{table} 表5.2 MARL 参数设置
:align: center
:widths: grid

| MARL 参数设置  |       |
|------------|-------|
| 时序差分学习率α   | 	0.01 |
| 衰减系数γ      | 	0.7  |
| Q-Table初始值 | 	0    |

:::
:::{table}
:align: center
:widths: grid
| ϵ-greedy探索参数设置 | |
|----------------|------|
| ϵ 初始值 | 0.8 |
| ϵ结束值 | 0 |
:::
